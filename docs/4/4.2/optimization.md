# 模型优化

- 编辑：李竹楠
- 日期：2024/02/13

## 1. 正则化(Regularization)

### 1.1 介绍

在机器学习中，模型最终的目的是使算法在训练数据集和任何新样本或测试数据集上的表现都一样好。在机器学习中使用的技术被称为正则化(regularization)，**专门设计用于减少测试误差，主要以增加训练误差为代价**。

![](../../../pics/pics1/521.gif)

### 1.2 什么是正则化？

正则化可以定义为对学习算法进行任何修改或改变，以减少其在测试数据集上的误差（通常称为泛化误差(generalization error)）而不是在训练误差上。

在学习算法中，正则化技术有很多变体，每种都试图应对不同的挑战。根据该技术试图解决的挑战，可以直接列出这些挑战:

- 有些试图对机器学习模型的学习施加额外的约束，例如添加对参数值的范围/类型的限制。
- 有些在目标或成本函数中添加更多的项，就像对参数值的软约束。通常情况下，在成本函数中仔细选择正确的约束和惩罚有助于大幅提高模型的性能，特别是在测试数据集上。
- 这些额外的项也可以基于一些与数据集或问题陈述密切相关的先验信息进行编码。
- 最常用的正则化技术之一是创建集成模型，它将多个模型的集体决策考虑在内，每个模型都用不同的数据样本进行训练。

正则化的主要目的是降低机器学习模型的过度复杂性，并帮助模型学习更简单的函数以提高泛化能力。下图是正则化对模型的影响：

![](../../../pics/pics1/522.gif)

### 1.3 深度学习中的正则化

在深度学习模型中，大多数正则化策略都是围绕正则化估计器(regularizing estimators)展开的。现在问题来了正则化估计器是什么意思?

偏差与方差的权衡图更清楚地说明了这个问题：

![](../../../pics/pics1/523.webp)

estimators的正则化是通过增加偏差来减少方差的。**一个有效的正则化将是在偏差和方差之间进行最佳权衡，而权衡的最终结果应该是在偏差的最小代价下显著减少方差**。简单地说，这意味着低方差，而不大幅增加偏差值。

### 1.4 正则惩罚项

通过在损失函数 $J$ 中添加参数范数惩罚 $\Omega(\theta)$，神经网络、线性或逻辑回归等模型的能力受到限制。方程可以表示为:

$$
\tilde{J}(\theta; X, y)=J(\theta; X, y) + \alpha \Omega(\theta)
$$

其中，$\alpha$ 越大，对应的惩罚越大；反之，如果为0，则没有惩罚。这种类型的正则化只惩罚网络每一层的仿射变换的权重，从而使偏差没有正则化。这样做的想法是，拟合偏差通常需要比权重更少的数据。

### 1.5 L1正则化

L1正则化公式如下所示：

$$
Loss=Error(y, \hat{y}) + \lambda \sum^{N}_{i=1} \vert w_i \vert
$$

Lasso回归(Least Absolute Shrinkage and Selection Operator)将系数的“绝对值”作为损失函数的惩罚项。

**Lasso将不重要特征的系数缩小为零;因此，完全删除一些特征。因此，在特征数量很大的情况下，这适用于特征选择**。

L1正则项基本上是寻找使参数向量的范数(向量的长度)最小化的参数向量。这本质上是如何优化单个神经元的参数的问题，一般来说是单层神经网络，特别是单层前馈神经网络。

![](../../../pics/pics1/524.gif)

对它进行概念化的一个好方法是，它是一种最大化真实参数向量所在的参数超空间面积的方法。为此，它会找到“最锋利”的边缘，即尽可能接近参数向量的边缘。L1正则化需要注意的关键点:

### 1.6 L2正则化

如果使用L2正则化的回归则被称为岭回归(Ridge Regression)：

$$
Loss=Error(y, \hat{y}) + \lambda \sum^{N}_{i=1}w^2_i
$$

随着模型复杂度的增加，正则化会增加惩罚。正则化参数(lambda)惩罚除截距外的所有参数，使模型对数据泛化，不会过拟合。岭回归将“系数的平方”作为惩罚项添加到损失函数中。在这里，上图中的框部分代表L2正则化元素/项。

### 1.7 总结

## 2. 归一化(Normalization)

详见[Normalization](./normalization.md)。

## 3. 梯度下降

### 3.1 随机梯度下降(Stochastic Gradient Descent, SGD)

### 3.2 Mini梯度下降(Mini-batch Gradient Descent, MBGD)

### 3.3 批梯度下降(Batch Gradient Descent, BGD)

## 学习率

## 参数初始化

## 超参数调优

## 面试题

### 怎么判断模型是否过拟合，有哪些防止过拟合的策略？

- 增加训练数据：获取更多数据，也可以使用图像增强、增样等；
- 使用合适的模型：适当减少网络的层数、降低网络参数量；
- Dropout：随机抑制网络中一部分神经元，使的每次训练都有一批神经元不参与模型训练；
- L1、L2正则化：训练时限制权值的大小，增加惩罚机制，使得网络更稀疏；
- 数据清洗：去除问题数据、错误标签和噪声数据；
- 限制网络训练时间：在训练时将训练集和验证集损失分别输出，当训练集损失持续下降，而验证集损失不再下降时，网络就开始出现过拟合现象，此时就可以停止训练了；
- 在网络中使用BN层（Batch Normalization）也可以一定程度上防止过拟合。

### 神经网络的正则化方法？过拟合的解决方法？

- 数据增强(镜像对称、随机裁剪、旋转图像、剪切图像、局部弯曲图像、色彩转换)
- early stopping(比较训练损失和验证损失曲线，验证损失最小即为最优迭代次数)
- L1、L2正则化
- dropout

### 什么是正则化？L1正则化和L2正则化有什么区别？

正则化(Regularization)是机器学习中对原始损失函数引入额外信息，以便防止过拟合和提高模型泛化性能的一类方法的统称。也就是目标函数变成了原始损失函数+惩罚项，常用的惩罚项一般有两种，英文称作L1-norm和L2-norm中文称作L1正则化和L2正则化，或者L1范数和L2范数。

L1正则化和L2正则化可以看做是损失函数的惩罚项。所谓惩罚是指对损失函数中的某些参数做一些限制。对于线性回归模型，使用L1正则化的模型叫做**Lasso回归**，使用L2正则化的模型叫做**Ridge回归（岭回归）**。

线性回归L1正则化损失函数：

$$
cost = \sum ^N_{i=1} (w^tx_i - y_i)^2 + \lambda \Vert w \Vert _1
$$

线性回归L2正则化损失函数：

$$
cost = \sum ^N_{i=1} (w^tx_i - y_i)^2 + \lambda \Vert w \Vert _2^2
$$

L1正则化是指权值向量 $w$ 中各个元素的绝对值之和，通常表示为 $\Vert w \Vert _1$，L2正则化是指权值向量 $w$ 中各个元素的平方和然后再求平方根，通常表示为 $\Vert w \Vert _1^2$

L1和L2的区别：

- L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择
- L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合

调参经验：从0开始，逐渐增大 $\lambda$。在训练集上学习到参数，然后在测试集上验证误差。反复进行这个过程，直到测试集上的误差最小。一般的说，随着 $\lambda$ 从0开始增大，测试集的误分类率应该是先减小后增大，交叉验证的目的，就是为了找到误分类率最小的那个位置。建议一开始将正则项系数 $\lambda$ 设置为0，先确定一个比较好的learning rate。然后固定该learning rate，给 $\lambda$ 一个值（比如1.0），然后根据validation accuracy，将λ增大或者减小10倍，增减10倍是粗调节，当你确定了 $\lambda$ 的合适的数量级后，比如 $\lambda = 0.01$，再进一步地细调节，比如调节为0.02，0.03，0.009之类。

参考：

- https://www.cnblogs.com/zingp/p/10375691.html
- https://beyondguo.github.io/dl_basis/notes/%E3%80%8C%E6%9D%82%E8%B0%88%E3%80%8D%E7%90%86%E8%A7%A3L1,%20L2%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF.html#%E4%BA%8C%E3%80%81%E6%9C%80%E5%90%8E%E8%BE%85%E4%BB%A5%E6%8E%A8%E5%AF%BC

### dropout为什么能解决过拟合？

正常神经网络需要对每一个节点进行学习，而添加了DropOut的神经网络通过删除部分单元（随机），即暂时将其从网络中移除，以及它的所有传入和传出连接。将DropOut应用于神经网络相当于从神经网络中采样了一个“更薄的”网络，即单元个数较少。在神经网络的训练过程中，对于一次迭代中的某一层神经网络，先随机选择其中的一些神经元并将其临时丢弃，然后再进行本次的训练和优化。在下一次迭代中，继续随机隐藏一些神经元，直至训练结束。由于是随机丢弃，故而每一个批次都在训练不同的网络。可以防止参数过分依赖训练数据，减少神经元之间复杂的共适应关系，增加参数对数据集的泛化能力。

### 除了SGD和Adam之外，你还知道哪些优化算法？

主要有三大类：
- 基本梯度下降法，包括 GD(Gradient Descent)，BGD(Batch Gradient Descent)，SGD(Stochastic Gradient Descent)；
- 动量优化法，包括 Momentum，NAG 等；
- 自适应学习率优化法，包括 Adam，AdaGrad，RMSProp 等。

- Momentum：解决随机梯度下降（SGD）算法在更新参数时可能面临的一些问题，如收敛速度慢、易陷入局部最优解等。Momentum的核心思想是引入**动量项**，该项考虑了之前梯度的加权平均值。具体而言，对于每个参数的更新，Momentum算法**考虑了上一次更新的方向**，并根据这个方向在当前步骤的梯度方向上增加一个动量项。这有助于加速在平坦区域和减小梯度方向变化的情况下的收敛速度，并有助于**跳过一些局部极小值**。
- Adam
- AdaGrad
- RMSProp

### 训练神经网络有哪些调参技巧？

参考：

- https://mp.weixin.qq.com/s/lmh0J-to5V8jylPWeUymzQ

### 随机梯度下降相比全局梯度下降好处是什么？

- Batch gradient descent：优点是理想状态下经过足够多的迭代后可以达到全局最优。但是缺点也很明显，就是如果你的数据集非常的大（现在很常见），根本没法全部塞到内存（显存）里，所以BGD对于小样本还行，大数据集就无法运行了。而且因为每次迭代都要计算全部的样本，所以对于大数据量会非常的慢。
- gradient descent：为了加快收敛速度，并且解决大数据量无法一次性塞入内存（显存）的问题，stochastic gradient descent（SGD）就被提出来了，SGD的思想是每次只训练一个样本去更新参数。但是SGD也有缺点，因为每次只用一个样本来更新参数，会导致不稳定性大些，每次更新的方向，不像batch gradient descent那样每次都朝着最优点的方向逼近，会在最优点附近震荡。因为每次训练的都是随机的一个样本，会导致导致梯度的方向不会像BGD那样朝着最优点。
- stochastic gradient descent：mini-batch gradient descent 是batch gradient descent和stochastic gradient descent的折中方案，就是mini-batch gradient descent每次用一部分样本来更新参数。

### 为什么要对网络进行初始化，有哪些初始化的方法？

权重初始化的目的是防止在深度神经网络的正向（前向）传播过程中层激活函数的输出损失梯度出现爆炸或消失。如果发生任何一种情况，损失梯度太大或太小，就无法有效地向后传播，并且即便可以向后传播，网络也需要花更长时间来达到收敛。

- 所有的参数初始化为0或者相同的常数
- 随机参数初始化
- He initialization

### 如果在网络初始化时给网络赋予0的权重，这个网络能正常训练吗？

不可以，最简单的初始化方法就是将权值参数全部初始化为0或者一个常数，但是使用这种方法会导致网络中所有的神经元学习到的是相同的特征。换句话说，如果参数进行了全零的参数化，那么网络神经元将无法训练模型。

### 梯度消失和梯度爆炸的原因是什么？

- 梯度消失：权重参数呈指数级减小，往往出现在深层网络中或者采用了不合适的损失函数，比如sigmoid。
- 梯度爆炸：权重参数呈指数级增长，一般出现在深层网络和权值初始化值太大的情况下。

参考：

- https://blog.csdn.net/qq_25737169/article/details/78847691

### 常见的损失函数有哪些？你用过哪些？

### 深度学习中的batch的大小对学习效果有何影响？

### 数据不平衡的解决方法

### 有什么数据增强的方式？

- 单样本几何变换：翻转，旋转，裁剪，缩放
- 单样本像素内容变换：噪声，模糊，颜色扰动
- 多样本插值 Mixup：图像和标签都进行线性插值

### 为什么在模型训练开始会有warm up？

warm up, 在刚刚开始训练时以很小的学习率进行训练，使得网络熟悉数据，随着训练的进行学习率慢慢变大，到了一定程度，以设置的初始学习率进行训练，接着过了一些inter后，学习率再慢慢变小；学习率变化：上升——平稳——下降。有助于减缓模型在初始阶段对mini-batch的提前过拟合现象，保持分布的平稳；有助于保持模型深层的稳定性。

### Batch Normalization 和 Layer Normalization


