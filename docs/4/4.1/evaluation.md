# 模型评估方法与准则

- 编辑：李竹楠
- 日期：2024/02/04

在AI场景下我们需要定量的数值化指标来指导我们更好地应用模型对数据进行学习和建模。事实上，在机器学习领域，对模型的测量和评估至关重要。选择与问题相匹配的评估方法，能帮助我们快速准确地发现在模型选择和训练过程中出现的问题，进而对模型进行优化和迭代。

## 1. 模型评估的目标

**模型评估的目标是选出泛化能力强的模型完成机器学习任务**。实际的机器学习任务往往需要进行大量的实验，经过反复调参、使用多种模型算法（甚至多模型融合策略）来完成自己的机器学习问题，并观察哪种模型算法在什么样的参数下能够最好地完成任务。

**泛化能力强**的模型能很好地适用于未知的样本，模型的错误率低、精度高。机器学习任务中，我们希望最终能得到**准确预测未知标签的样本、泛化能力强的模型**。但是我们无法提前获取“未知的样本”，因此我们会基于已有的数据进行切分来完成模型训练和评估，借助于切分出的数据进行评估，可以很好地判定模型状态（过拟合或欠拟合），进而迭代优化。

在建模过程中，为了获得泛化能力强的模型，我们需要一整套方法及评价指标。

- **评估方法**：为保证客观地评估模型，对数据集进行的有效划分实验方法。
- **性能指标**：量化地度量模型效果的指标。

在介绍评估标准之前，需要了解一下概念。

## 2. 实验方法

## 3. 常见的模型评估方法

## 4. 回归问题常用的评估指标

### 回归评估指标适用场景

## 5. 分类问题常用的评估指标

### 分类评估指标适用场景

## 6. 样本均衡与采样

## 7. 面试题