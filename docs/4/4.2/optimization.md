# 模型优化

- 编辑：李竹楠
- 日期：2024/02/13

## 1. 优化的目标

## 2. 优化的挑战

## 3. 学习率

## 4. 梯度下降

## 5. 超参数调优

## Batch Normalization

### 1.2 正则化 (Regularization)

#### 1.3.1 岭回归 (Ridge 回归)

#### 1.3.2 LASSO回归 

## 面试题

### 怎么判断模型是否过拟合，有哪些防止过拟合的策略？

- 增加训练数据：获取更多数据，也可以使用图像增强、增样等；
- 使用合适的模型：适当减少网络的层数、降低网络参数量；
- Dropout：随机抑制网络中一部分神经元，使的每次训练都有一批神经元不参与模型训练；
- L1、L2正则化：训练时限制权值的大小，增加惩罚机制，使得网络更稀疏；
- 数据清洗：去除问题数据、错误标签和噪声数据；
- 限制网络训练时间：在训练时将训练集和验证集损失分别输出，当训练集损失持续下降，而验证集损失不再下降时，网络就开始出现过拟合现象，此时就可以停止训练了；
- 在网络中使用BN层（Batch Normalization）也可以一定程度上防止过拟合。

### 神经网络的正则化方法？过拟合的解决方法？

- 数据增强(镜像对称、随机裁剪、旋转图像、剪切图像、局部弯曲图像、色彩转换)
- early stopping(比较训练损失和验证损失曲线，验证损失最小即为最优迭代次数)
- L1、L2正则化
- dropout

### 什么是正则化？L1正则化和L2正则化有什么区别？

正则化(Regularization)是机器学习中对原始损失函数引入额外信息，以便防止过拟合和提高模型泛化性能的一类方法的统称。也就是目标函数变成了原始损失函数+惩罚项，常用的惩罚项一般有两种，英文称作L1-norm和L2-norm中文称作L1正则化和L2正则化，或者L1范数和L2范数。

L1正则化和L2正则化可以看做是损失函数的惩罚项。所谓惩罚是指对损失函数中的某些参数做一些限制。对于线性回归模型，使用L1正则化的模型叫做**Lasso回归**，使用L2正则化的模型叫做**Ridge回归（岭回归）**。

线性回归L1正则化损失函数：

$$
cost = \sum ^N_{i=1} (w^tx_i - y_i)^2 + \lambda \Vert w \Vert _1
$$

线性回归L2正则化损失函数：

$$
cost = \sum ^N_{i=1} (w^tx_i - y_i)^2 + \lambda \Vert w \Vert _2^2
$$

L1正则化是指权值向量 $w$ 中各个元素的绝对值之和，通常表示为 $\Vert w \Vert _1$，L2正则化是指权值向量 $w$ 中各个元素的平方和然后再求平方根，通常表示为 $\Vert w \Vert _1^2$

L1和L2的区别：

- L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择
- L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合

调参经验：从0开始，逐渐增大 $\lambda$。在训练集上学习到参数，然后在测试集上验证误差。反复进行这个过程，直到测试集上的误差最小。一般的说，随着 $\lambda$ 从0开始增大，测试集的误分类率应该是先减小后增大，交叉验证的目的，就是为了找到误分类率最小的那个位置。建议一开始将正则项系数 $\lambda$ 设置为0，先确定一个比较好的learning rate。然后固定该learning rate，给 $\lambda$ 一个值（比如1.0），然后根据validation accuracy，将λ增大或者减小10倍，增减10倍是粗调节，当你确定了 $\lambda$ 的合适的数量级后，比如 $\lambda = 0.01$，再进一步地细调节，比如调节为0.02，0.03，0.009之类。

参考：

- https://www.cnblogs.com/zingp/p/10375691.html
- https://beyondguo.github.io/dl_basis/notes/%E3%80%8C%E6%9D%82%E8%B0%88%E3%80%8D%E7%90%86%E8%A7%A3L1,%20L2%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF.html#%E4%BA%8C%E3%80%81%E6%9C%80%E5%90%8E%E8%BE%85%E4%BB%A5%E6%8E%A8%E5%AF%BC

### dropout为什么能解决过拟合？

正常神经网络需要对每一个节点进行学习，而添加了DropOut的神经网络通过删除部分单元（随机），即暂时将其从网络中移除，以及它的所有传入和传出连接。将DropOut应用于神经网络相当于从神经网络中采样了一个“更薄的”网络，即单元个数较少。在神经网络的训练过程中，对于一次迭代中的某一层神经网络，先随机选择其中的一些神经元并将其临时丢弃，然后再进行本次的训练和优化。在下一次迭代中，继续随机隐藏一些神经元，直至训练结束。由于是随机丢弃，故而每一个批次都在训练不同的网络。可以防止参数过分依赖训练数据，减少神经元之间复杂的共适应关系，增加参数对数据集的泛化能力。

### 除了SGD和Adam之外，你还知道哪些优化算法？

主要有三大类：
- 基本梯度下降法，包括 GD(Gradient Descent)，BGD(Batch Gradient Descent)，SGD(Stochastic Gradient Descent)；
- 动量优化法，包括 Momentum，NAG 等；
- 自适应学习率优化法，包括 Adam，AdaGrad，RMSProp 等。

- Momentum：解决随机梯度下降（SGD）算法在更新参数时可能面临的一些问题，如收敛速度慢、易陷入局部最优解等。Momentum的核心思想是引入**动量项**，该项考虑了之前梯度的加权平均值。具体而言，对于每个参数的更新，Momentum算法**考虑了上一次更新的方向**，并根据这个方向在当前步骤的梯度方向上增加一个动量项。这有助于加速在平坦区域和减小梯度方向变化的情况下的收敛速度，并有助于**跳过一些局部极小值**。
- Adam
- AdaGrad
- RMSProp

### 训练神经网络有哪些调参技巧？

参考：

- https://mp.weixin.qq.com/s/lmh0J-to5V8jylPWeUymzQ

### 随机梯度下降相比全局梯度下降好处是什么？

- Batch gradient descent：优点是理想状态下经过足够多的迭代后可以达到全局最优。但是缺点也很明显，就是如果你的数据集非常的大（现在很常见），根本没法全部塞到内存（显存）里，所以BGD对于小样本还行，大数据集就无法运行了。而且因为每次迭代都要计算全部的样本，所以对于大数据量会非常的慢。
- gradient descent：为了加快收敛速度，并且解决大数据量无法一次性塞入内存（显存）的问题，stochastic gradient descent（SGD）就被提出来了，SGD的思想是每次只训练一个样本去更新参数。但是SGD也有缺点，因为每次只用一个样本来更新参数，会导致不稳定性大些，每次更新的方向，不像batch gradient descent那样每次都朝着最优点的方向逼近，会在最优点附近震荡。因为每次训练的都是随机的一个样本，会导致导致梯度的方向不会像BGD那样朝着最优点。
- stochastic gradient descent：mini-batch gradient descent 是batch gradient descent和stochastic gradient descent的折中方案，就是mini-batch gradient descent每次用一部分样本来更新参数。

### 为什么要对网络进行初始化，有哪些初始化的方法？

权重初始化的目的是防止在深度神经网络的正向（前向）传播过程中层激活函数的输出损失梯度出现爆炸或消失。如果发生任何一种情况，损失梯度太大或太小，就无法有效地向后传播，并且即便可以向后传播，网络也需要花更长时间来达到收敛。

- 所有的参数初始化为0或者相同的常数
- 随机参数初始化
- He initialization

### 如果在网络初始化时给网络赋予0的权重，这个网络能正常训练吗？

不可以，最简单的初始化方法就是将权值参数全部初始化为0或者一个常数，但是使用这种方法会导致网络中所有的神经元学习到的是相同的特征。换句话说，如果参数进行了全零的参数化，那么网络神经元将无法训练模型。

### 梯度消失和梯度爆炸的原因是什么？

- 梯度消失：权重参数呈指数级减小，往往出现在深层网络中或者采用了不合适的损失函数，比如sigmoid。
- 梯度爆炸：权重参数呈指数级增长，一般出现在深层网络和权值初始化值太大的情况下。

参考：

- https://blog.csdn.net/qq_25737169/article/details/78847691

### 常见的损失函数有哪些？你用过哪些？

### 深度学习中的batch的大小对学习效果有何影响？

### 数据不平衡的解决方法

### 有什么数据增强的方式？

- 单样本几何变换：翻转，旋转，裁剪，缩放
- 单样本像素内容变换：噪声，模糊，颜色扰动
- 多样本插值 Mixup：图像和标签都进行线性插值

### 为什么在模型训练开始会有warm up？

warm up, 在刚刚开始训练时以很小的学习率进行训练，使得网络熟悉数据，随着训练的进行学习率慢慢变大，到了一定程度，以设置的初始学习率进行训练，接着过了一些inter后，学习率再慢慢变小；学习率变化：上升——平稳——下降。有助于减缓模型在初始阶段对mini-batch的提前过拟合现象，保持分布的平稳；有助于保持模型深层的稳定性。

### Batch Normalization 和 Layer Normalization


